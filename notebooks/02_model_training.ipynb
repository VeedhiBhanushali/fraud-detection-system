{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Validation Performance:\n",
      "Precision: 1.000, Recall: 0.935, F1: 0.966, Accuracy: 1.000\n",
      "Model training complete. Best model saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Load processed data\n",
    "train_df = pd.read_csv('../data/train_processed_transactions.csv')\n",
    "val_df = pd.read_csv('../data/val_processed_transactions.csv')\n",
    "test_df = pd.read_csv('../data/test_processed_transactions.csv')\n",
    "\n",
    "# Ensure all expected features are present\n",
    "expected_features = ['Amount', 'hour', 'dayofweek', 'txns_last_24h', 'amount_last_24h', 'risk_score']\n",
    "missing_features = [f for f in expected_features if f not in train_df.columns]\n",
    "\n",
    "if missing_features:\n",
    "    raise ValueError(f\"Missing expected features in dataset: {missing_features}\")\n",
    "\n",
    "# Feature selection\n",
    "X_train, y_train = train_df[expected_features], train_df['Class']\n",
    "X_val, y_val = val_df[expected_features], val_df['Class']\n",
    "X_test, y_test = test_df[expected_features], test_df['Class']\n",
    "\n",
    "### Apply ADASYN for Oversampling Fraud Cases ###\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=5)\n",
    "X_train_balanced, y_train_balanced = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# **LightGBM Configuration**\n",
    "best_model = LGBMClassifier(\n",
    "    n_estimators=1000,  \n",
    "    max_depth=12,  \n",
    "    learning_rate=0.05,\n",
    "    num_leaves=50,  \n",
    "    min_gain_to_split=0.0,  \n",
    "    min_child_samples=1,  \n",
    "    min_data_in_leaf=1, \n",
    "    reg_alpha=0,  \n",
    "    reg_lambda=0,  \n",
    "    colsample_bytree=1.0,  \n",
    "    subsample=1.0,  \n",
    "    force_col_wise=True,  \n",
    "    verbose=-1,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "best_model.fit(X_train_balanced, y_train_balanced)\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate Model\n",
    "final_prec = precision_score(y_val, y_val_pred)\n",
    "final_rec = recall_score(y_val, y_val_pred)\n",
    "final_f1 = f1_score(y_val, y_val_pred)\n",
    "final_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"\\nFinal Validation Performance:\")\n",
    "print(f\"Precision: {final_prec:.3f}, Recall: {final_rec:.3f}, F1: {final_f1:.3f}, Accuracy: {final_acc:.3f}\")\n",
    "\n",
    "# Save Model\n",
    "joblib.dump(best_model, '../src/fraud_detection_model.pkl')\n",
    "\n",
    "print(\"Model training complete. Best model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
